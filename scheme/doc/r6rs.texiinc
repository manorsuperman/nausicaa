@node r6rs
@chapter Tools for handling @rnrs{6} source code


The libraries under the @library{nausicaa r6rs ---} hierarchy provide
tools to manipulate Scheme source code compliant with the @rnrs{6}
standard.

@menu
* r6rs lexer::                  Tokenising @rnrs{6} source code.
* r6rs fixed-strings::          A collection of common strings.
@end menu

@c page
@node r6rs lexer
@section Tokenising @rnrs{6} source code


The library @library{nausicaa r6rs lexer} implements a lexer compliant
with the @rnrs{6} specification for Scheme source code.  The lexer is
built on top of the @library{nausicaa silex} parser generator;
@ref{silex} for details.

@menu
* r6rs lexer full::             Full lexer table.
* r6rs lexer params::           Full lexer semantic action parameters.
* r6rs lexer makers::           Full lexer token makers.
* r6rs lexer strings::          Reading strings.
* r6rs lexer characters::       Reading characters.
* r6rs lexer identifiers::      Reading identifiers.
* r6rs lexer numbers::          Reading numbers.
* r6rs lexer nested comments::  Reading nested comments.
* r6rs lexer line comments::    Reading line comments.
@end menu

@c page
@node r6rs lexer full
@subsection Full source code lexer


@cindex Reading Scheme source code
@cindex Lexer, Scheme source code
@cindex Scheme source code, reading
@cindex Scheme source code, lexer
@cindex Source code of Scheme, lexer
@cindex Source code of Scheme, reader


The full @rnrs{6} source code lexer makes heavy use of parametrised
functions to allow customisation of the tokens.  The following bindings
are exported by the @library{nausicaa r6rs lexer} library.


@defvr Constant r6rs-lexer-table
A lexer table to parse @rnrs{6} compliant Scheme source code.  This
table needs an input system configured with @code{(counters: 'all)}.
The semantic action forms make use of the parameters documented in this
chapter to build the lexical tokens; @ref{r6rs lexer params} for
details.
@end defvr


@defun make-token-lexer @var{IS}
@defunx make-token-lexer @var{IS} @var{lexer-table}
A lexer function generator for full @rnrs{6} source code reading.  Given
an input system @var{IS} build and return a lexer function using the
@var{lexer-table}, which defaults to @code{r6rs-lexer-table}.

The definition of this function is a good example of full table usage;
notice that strings and nested comments are read with
@func{read-string*} and @func{read-nested-comment*} respectively:

@example
(define make-token-lexer
  (case-lambda
   ((IS)
    (make-token-lexer IS r6rs-lexer-table))
   ((IS lexer-table)
    (let ((lexer (lexer-make-lexer lexer-table IS)))
      (lambda ()
        (let next (((T <lexical-token>) (lexer)))
          (define (%string-token)
            (let ((S (read-string* IS)))
              (if (string? S)
                  ((string-token-maker)
                     (lexer-get-func-getc IS)
                     (lexer-get-func-ungetc IS)
                     S T.location.line
                     T.location.column T.location.offset)
                S)))
          (define (%nested-comment-token)
            (let ((S (read-nested-comment* IS)))
              (if (string? S)
                  ((nested-comment-token-maker)
                     (lexer-get-func-getc IS)
                     (lexer-get-func-ungetc IS)
                     S T.location.line
                     T.location.column T.location.offset)
                S)))
          (cond (T.special? T)
                ((eq? T.category 'WHITESPACE)
                 (next (lexer)))
                ((eq? T.category 'LINEENDING)
                 (next (lexer)))
                ((eq? T.category 'DOUBLEQUOTE)
                 (%string-token))
                ((eq? T.category 'ONESTEDCOMMENT)
                 (%nested-comment-token))
                (else T))))))))
@end example
@end defun


Here is how to test the lexer function maker:

@example
#!r6rs
(import (nausicaa)
  (nausicaa r6rs lexer)
  (nausicaa silex lexer)
  (nausicaa silex lexeme-processing)
  (nausicaa parser-tools lexical-token)
  (nausicaa parser-tools source-location))

(define (tokenise string)
  (let* ((IS     (lexer-make-IS (string: string)
                                (counters: 'all)))
         (lexer  (make-token-lexer IS)))
    (let next (((T <lexical-token>) (lexer))
               (result              '()))
      (cond (T.lexer-error?
             (reverse `((,T.category ,T.value)
                        . ,result)))
            (T.end-of-input?
             (reverse `(*eoi* . ,result)))
            (else
             (next (lexer) `((,T.category ,T.value)
                             . ,result)))))))

(tokenise "( \"ciao\" ciao 123 )")
@result{} ((OPAREN #\()
    (STRING "ciao")
    (IDENTIFIER "ciao")
    (NUMBER 123)
    (CPAREN #\))
    *eoi*)

(let ((mt (lambda (yygetc yyungetc yytext yyline yycolumn yyoffset)
            (make* <lexical-token>
              'THE-IDENTIFIER
              (make* <source-location>
                (current-input-source)
                yyline yycolumn yyoffset)
              (string->symbol yytext)
              (string-length yytext)))))
  (parametrise ((identifier-token-maker mt))
    (tokenise "( \"ciao\" ciao 123 )")))
@result{} ((OPAREN #\()
    (STRING "ciao")
    (THE-IDENTIFIER ciao)
    (NUMBER 123)
    (CPAREN #\))
    *eoi*)
@end example

@c page
@node r6rs lexer params
@subsection Full lexer table semantic action parameters


Some of the bindings exported by the library @library{nausicaa r6rs
lexeme-processing} reference parameter functions as defined by
@library{nausicaa language parameters}.  The semantic action forms in
the full @rnrs{6} lexer table, @code{r6rs-lexer-table}, invoke the
functions referenced by the parameters to produce lexical tokens.

All the parameters whose name has the @code{-token-maker} suffix are
used as follows in the semantic action forms:

@example
((open-paren-token-maker)
    yygetc yyungetc yytext yyline yycolumn yyoffset)
@end example

@noindent
and they must be set to functions with the following (or equivalent)
behaviour:

@example
(lambda (yygetc yyungetc yytext yyline yycolumn yyoffset)
  (make <lexical-token> ---))
@end example

@noindent
where the arguments are the bindings handed by @library{nausicaa silex
lexer} to the semantic action forms; @ref{silex semantics action} for
details.

Notice that it is perfectly possible to subclass @class{lexical-token}
and make the functions return instances of the subclass.  Also, it is
not strictly needed to return @class{lexical-token} records, altough
they help at least in tracking the location of values in the source
code.

@menu
* r6rs lexer params general::   General token maker parameters.
* r6rs lexer params fixed::     Fixed semantic value token maker
                                parameters.
* r6rs lexer params variable::  Variable semantic value token maker
                                parameters.
* r6rs lexer params scheme::    Scheme semantic value token maker
                                parameters.
* r6rs lexer params special::   Special token maker parameters.
@end menu

@c page
@node r6rs lexer params general
@subsubsection General token maker parameters


The following bindings are exported by the library @library{nausicaa
r6rs lexeme-processing}.


@deffn Parameter current-input-source
Hold the value representing the current input source; to be used to fill
the @code{input} field of @class{source-location} records.  The default
value is @false{}.  Currently there are no constraints on this value: it
can be anything.
@end deffn


@deffn Parameter eoi-token-maker
Set to a function returning a @class{lexical-token} record representing
the end--of--input.  The default is @func{make-eoi-token}.
@end deffn


@deffn Parameter lexical-error-token-maker
Set to a function returning a @class{lexical-token} record representing
a lexical error.  The default is @func{make-lexical-error-token}.
@end deffn

@c page
@node r6rs lexer params fixed
@subsubsection Fixed semantic value token maker parameters


The following bindings are exported by the library @library{nausicaa
r6rs lexeme-processing}.


@deffn Parameter open-paren-token-maker
Set to a function returning a @class{lexical-token} record representing
an open parenthesis, @samp{(} .  The default is
@func{make-open-paren-token}.
@end deffn


@deffn Parameter close-paren-token-maker
Set to a function returning a @class{lexical-token} record representing
a close parenthesis, @samp{)}.  The default is
@func{make-close-paren-token}.
@end deffn


@deffn Parameter open-bracket-token-maker
Set to a function returning a @class{lexical-token} record representing
an open bracket, @samp{[}.  The default is
@func{make-open-bracket-token}.
@end deffn


@deffn Parameter close-bracket-token-maker
Set to a function returning a @class{lexical-token} record representing
a close bracket, @samp{[}.  The default is
@func{make-close-bracket-token}.
@end deffn


@deffn Parameter tick-token-maker
Set to a function returning a @class{lexical-token} record representing
a tick, @samp{'}.  The default is @func{make-tick-token}.
@end deffn


@deffn Parameter back-tick-token-maker
Set to a function returning a @class{lexical-token} record representing
a back tick, @samp{`}.  The default is @func{make-back-tick-token}.
@end deffn


@deffn Parameter comma-at-token-maker
Set to a function returning a @class{lexical-token} record representing
a comma--at, @samp{,@@}.  The default is @func{make-comma-at-token}.
@end deffn


@deffn Parameter comma-token-maker
Set to a function returning a @class{lexical-token} record representing
a comma, @samp{,}.  The default is @func{make-comma-token}.
@end deffn


@deffn Parameter dot-token-maker
Set to a function returning a @class{lexical-token} record representing
a dot, @samp{.}.  The default is @func{make-dot-token}.
@end deffn


@deffn Parameter double-quote-token-maker
Set to a function returning a @class{lexical-token} record representing
a double quote, @samp{"}; double quotes open strings, which must be read
with a separate lexer table.  The default is
@func{make-double-quote-token}.
@end deffn


@deffn Parameter sharp-paren-token-maker
Set to a function returning a @class{lexical-token} record representing
a sharp--open parenthesis, @samp{#(}.  The default is
@func{make-sharp-paren-token}.
@end deffn


@deffn Parameter sharp-vu8-paren-token-maker
Set to a function returning a @class{lexical-token} record representing
a sharp--vu8--open parenthesis, @samp{#vu8(}.  The default is
@func{make-sharp-vu8-paren-token}.
@end deffn


@deffn Parameter sharp-tick-token-maker
Set to a function returning a @class{lexical-token} record representing
a sharp--tick, @samp{#'}.  The default is @func{make-sharp-tick-token}.
@end deffn


@deffn Parameter sharp-back-tick-token-maker
Set to a function returning a @class{lexical-token} record representing
a sharp--back tick, @samp{#`}.  The default is
@func{make-sharp-back-tick-token}.
@end deffn


@deffn Parameter sharp-comma-at-token-maker
Set to a function returning a @class{lexical-token} record representing
a sharp--commma--at, @samp{#,@@}.  The default is
@func{make-sharp-comma-at-token}.
@end deffn


@deffn Parameter sharp-comma-token-maker
Set to a function returning a @class{lexical-token} record representing
a sharp--comma, @samp{#,}.  The default is
@func{make-sharp-comma-token}.
@end deffn


@deffn Parameter sharp-semicolon-token-maker
Set to a function returning a @class{lexical-token} record representing
a sharp--semicolon, @samp{#;}.  The default is
@func{make-sharp-semicolon-token}.
@end deffn


@deffn Parameter open-nested-comment-token-maker
Set to a function returning a @class{lexical-token} record representing
the opening of a nested comment, @samp{#|}.  The default is
@func{make-open-nested-comment-token}.
@end deffn


@deffn Parameter sharp-bang-r6rs-token-maker
Set to a function returning a @class{lexical-token} record representing
a @samp{#!r6rs} token.  The default is
@func{make-sharp-bang-r6rs-token}.
@end deffn


@deffn Parameter sharp-bang-token-maker
Set to a function returning a @class{lexical-token} record representing
a sharp--bang, @samp{#!}; this token should be followed by an
identifier.  The default is @func{make-sharp-bang-token}.
@end deffn

@c page
@node r6rs lexer params variable
@subsubsection Variable semantic value token maker parameters


The following bindings are exported by the library @library{nausicaa
r6rs lexeme-processing}.


@deffn Parameter line-comment-token-maker
Set to a function returning a @class{lexical-token} record representing
a line comment with line--ending included, @samp{; ---}.  The default is
@func{make-line-comment-token}.
@end deffn


@deffn Parameter line-comment-noend-token-maker
Set to a function returning a @class{lexical-token} record representing
a line comment without line--ending; only end--of--input should be
allowed after this token.  The default is
@func{make-line-comment-noend-token}.
@end deffn


@deffn Parameter white-space-token-maker
Set to a function returning a @class{lexical-token} record representing
a white space.  The default is @func{make-white-space-token}.
@end deffn


@deffn Parameter line-ending-token-maker
Set to a function returning a @class{lexical-token} record representing
a line ending.  The default is @func{make-line-ending-token}.
@end deffn

@c page
@node r6rs lexer params scheme
@subsubsection Scheme semantic value token maker parameters


The following bindings are exported by the library @library{nausicaa
r6rs lexeme-processing}.


@deffn Parameter identifier-token-maker
Set to a function returning a @class{lexical-token} record representing
an identifier.  The default is @func{make-identifier-token}.
@end deffn


@deffn Parameter boolean-token-maker
Set to a function returning a @class{lexical-token} record representing
a boolean value.  The default is @func{make-boolean-token}.
@end deffn


@deffn Parameter named-character-token-maker
Set to a function returning a @class{lexical-token} record representing
a named character, for example @samp{#\newline}.  The default is
@func{make-named-character-token}.
@end deffn


@deffn Parameter hex-character-token-maker
Set to a function returning a @class{lexical-token} record representing
a hex character, for example @samp{#\x005C}.  The default is
@func{make-hex-character-token}.
@end deffn


@deffn Parameter literal-character-token-maker
Set to a function returning a @class{lexical-token} record representing
a literal character, for example @samp{#\A}.  The default is
@func{make-literal-character-token}.
@end deffn


@deffn Parameter number-token-maker
Set to a function returning a @class{lexical-token} record representing
a number.  The default is @func{make-number-token}.
@end deffn

@c page
@node r6rs lexer params special
@subsubsection Special token maker parameters


The following parameters are @strong{not} used directly by the semantic
action forms of @code{r6rs-lexer-table}: this table directly process
neither strings nor nested comments; rather is produces lexical tokens
for double quote characters (which open strings) and nested comment
opening sequences, @samp{#|}.  A full @rnrs{6} lexer must recognise such
opening tokens and switch table to process strings and nested comments,
for example using @func{read-string} and @func{read-nested-comment} from
@library{nausicaa r6rs lexer}.

The following bindings are exported by the library @library{nausicaa
r6rs lexeme-processing}.  See @func{make-token-lexer} for an example
usage of these parameters.


@deffn Parameter string-token-maker
Set to a function returning a @class{lexical-token} record representing
a string.  The default is @func{make-string-token}.
@end deffn


@deffn Parameter nested-comment-token-maker
Set to a function returning a @class{lexical-token} record representing
a nested comment.  The default is @func{make-nested-comment-token}.
@end deffn

@c page
@node r6rs lexer makers
@subsection Full lexer table token makers


The bindings documented in this section are exported by the
@library{nausicaa r6rs lexeme-processing} library; the functions are the
default token makers, used to build @class{lexical-token} records
representing lexemes from the input.

All the functions build and return instances of @class{lexical-token}
records; all the functions make use of the @func{current-input-source}
parameter to fill the @code{input} field of @class{source-location}
records.

When a function cannot return a Scheme token, because the input string
is incorrect: it makes use of the @func{lexical-error-token-maker}
parameter to build and return a @class{lexical-token} record
representing a lexer error.  This happens, for example, if the hex
character string holds a hex number out of range for Unicode.

All the functions have the following behaviour:

@example
(lambda (yygetc yyungetc yytext yyline yycolumn yyoffset)
  (make <lexical-token> ---))
@end example

@noindent
where the arguments are the bindings handed by @library{nausicaa silex
lexer} to the semantic action forms; @ref{silex semantics action} for
details.

Here is a summary of the lexical token categories:

@example
*eoi*                   *lexer-error*
BACKTICK                BOOLEAN
CBRACKET                CHARACTER
COMMA                   COMMAAT
CPAREN                  DOT
DOUBLEQUOTE             IDENTIFIER
LINECOMMENT             LINEENDING
NESTED-COMMENT          NUMBER
OBRACKET                ONESTEDCOMMENT
OPAREN                  SHARPBACKTICK
SHARPBANG               SHARPBANGR6RS
SHARPCOMMA              SHARPCOMMAAT
SHARPPAREN              SHARPSEMICOLON
SHARPTICK               SHARPVU8PAREN
STRING                  TICK
WHITESPACE
@end example

@menu
* r6rs lexer makers general::   General token makers.
* r6rs lexer makers fixed::     Fixed semantic value token makers.
* r6rs lexer makers variable::  Variable semantic value token makers.
* r6rs lexer makers scheme::    Scheme semantic value token makers.
* r6rs lexer makers special::   Special token makers.
@end menu

@c page
@node r6rs lexer makers general
@subsubsection General token makers


The following bindings are exported by the library @library{nausicaa
r6rs lexeme-processing}.


@defun make-eoi-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing the end--of--input.
The category is set to the symbol @code{*value*}; the semantic value is
set to @code{(eof-object)}.
@end defun


@defun make-lexical-error-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a lexical error.  The
category is set to the symbol @code{*lexer-error*}; the semantic value
is set to the Scheme string representing the input which caused the
error.
@end defun

@c page
@node r6rs lexer makers fixed
@subsubsection Fixed semantic value token makers


The following bindings are exported by the library @library{nausicaa
r6rs lexeme-processing}.  All the functions make use of the fixed
strings from @library{nausicaa r6rs fixed-strings} as semantic values;
@ref{r6rs fixed-strings} for details.


@defun make-open-paren-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing an open parenthesis,
@samp{(}.  The category is set to the symbol @code{OPAREN}; the semantic
value is set to the character @code{#\(}.
@end defun


@defun make-close-paren-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a close parenthesis,
@samp{)}.  The category is set to the symbol @code{CPAREN}; the semantic
value is set to the character @code{#\)}.
@end defun


@defun make-open-bracket-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing an open bracket,
@samp{[}.  The category is set to the symbol @code{OBRACKET}; the
semantic value is set to the character @code{#\[}.
@end defun


@defun make-close-bracket-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a close bracket,
@samp{[}.  The category is set to the symbol @code{CBRACKET}; the
semantic value is set to the character @code{#\]}.
@end defun


@defun make-tick-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a tick, @samp{'}.
The category is set to the symbol @code{TICK}; the semantic value is set
to the character @code{#\'}.
@end defun


@defun make-back-tick-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a back tick,
@samp{`}.  The category is set to the symbol @code{BACKTICK}; the
semantic value is set to the character @code{#\`}.
@end defun


@defun make-comma-at-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a comma--at,
@samp{,@@}.  The category is set to the symbol @code{COMMAAT}; the
semantic value is set to the string @code{",@"}.
@end defun


@defun make-comma-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a comma, @samp{,}.
The category is set to the symbol @code{COMMA}; the semantic value is
set to the character @code{#\,}.
@end defun


@defun make-dot-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a dot, @samp{.}.  The
category is set to the symbol @code{DOT}; the semantic value is set to
the character @code{#\.}.
@end defun


@defun make-double-quote-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a double quote,
@samp{"}; double quotes open strings, which must be read with a separate
lexer table.  The category is set to the symbol @code{DOUBLEQUOTE}; the
semantic value is set to the character @code{#\"}.
@end defun


@defun make-sharp-paren-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a sharp--open
parenthesis, @samp{#(}.  The category is set to the symbol
@code{SHARPPAREN}; the semantic value is set to the string @code{"#("}.
@end defun


@defun make-sharp-vu8-paren-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a sharp--vu8--open
parenthesis, @samp{#vu8(}.  The category is set to the symbol
@code{SHARPVU8PAREN}; the semantic value is set to the string
@code{"#vu8("}.
@end defun


@defun make-sharp-tick-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a sharp--tick,
@samp{#'}.  The category is set to the symbol @code{SHARPTICK}; the
semantic value is set to the string @code{"#'"}.
@end defun


@defun make-sharp-back-tick-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a sharp--back tick,
@samp{#`}.  The category is set to the symbol @code{SHARPBACKTICK}; the
semantic value is set to the string @code{"#`"}.
@end defun


@defun make-sharp-comma-at-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a sharp--commma--at,
@samp{#,@@}.  The category is set to the symbol @code{SHARPCOMMAAT}; the
semantic value is set to the string @code{"#,@@"}.
@end defun


@defun make-sharp-comma-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a sharp--comma,
@samp{#,}.  The category is set to the symbol @code{SHARPCOMMA}; the
semantic value is set to the string @code{"#,"}.
@end defun


@defun make-sharp-semicolon-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a sharp--semicolon,
@samp{#;}.  The category is set to the symbol @code{SHARPSEMICOLON}; the
semantic value is set to the string @code{"#;"}.
@end defun


@defun make-open-nested-comment-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing the opening of a
nested comment, @samp{#|}.  The category is set to the symbol
@code{ONESTEDCOMMENT}; the semantic value is set to the string
@code{"#|"}.
@end defun


@defun make-sharp-bang-r6rs-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a @samp{#!r6rs}
token.  The category is set to the symbol @code{SHARPBANGR6RS}; the
semantic value is set to the string @code{"#!r6rs"}.
@end defun


@defun make-sharp-bang-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a sharp--bang,
@samp{#!}.  The category is set to the symbol @code{SHARPBANG}; the
semantic value is set to the string @code{"#!"}.
@end defun

@c page
@node r6rs lexer makers variable
@subsubsection Variable semantic value token makers


The following bindings are exported by the library @library{nausicaa
r6rs lexeme-processing}.


@defun make-line-comment-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a line comment with
line--ending included, @samp{; ---}.  The category is set to the symbol
@code{LINECOMMENT}; the semantic value is set to the string representing
the comment, line ending included.
@end defun


@defun make-line-comment-noend-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
The next character from the input system is peeked, if it is the end of
file: return a @class{lexical-token} record representing a line comment
without line--ending.  The category is set to the symbol
@code{LINECOMMENT}; the semantic value is set to the string representing
the comment.

If the next character from the input system is not the end of file:
apply the function referenced by the @func{lexical-error-token-maker}
parameter to the same arguments given to this function and return its
result.

If in the lexer table there is no error in the regular expression
matching a comment without line ending: the next character from the
input stream is always the end of file.
@end defun


@defun make-white-space-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a white space.  The
category is set to the symbol @code{WHITESPACE}; the semantic value is
set to the string representing the blank characters.
@end defun


@defun make-line-ending-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a line ending.  The
category is set to the symbol @code{LINEENDING}; the semantic value is
set to the string representing the line ending character or characters.
@end defun

@c page
@node r6rs lexer makers scheme
@subsubsection Scheme semantic value token makers


The following bindings are exported by the library @library{nausicaa
r6rs lexeme-processing}.


@defun make-identifier-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing an identifier.  The
category is set to the symbol @code{IDENTIFIER}; the semantic value is
set to the string representing the identifier.
@end defun


@defun make-boolean-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a boolean value.  The
category is set to the symbol @code{BOOLEAN}; the semantic value is set
to the boolean value.
@end defun


@defun make-named-character-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a named character,
for example @samp{#\newline}.  The category is set to the symbol
@code{CHARACTER}; the semantic value is set to the character itself.
@end defun


@defun make-hex-character-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a hex character, for
example @samp{#\x005C}.  The category is set to the symbol
@code{CHARACTER}; the semantic value is set to the character itself.
@end defun


@defun make-literal-character-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a literal character,
for example @samp{#\A}.  The category is set to the symbol
@code{CHARACTER}; the semantic value is set to the character itself.
@end defun


@defun make-number-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Return a @class{lexical-token} record representing a number.  The
category is set to the symbol @code{NUMBER}; the semantic value is set
to the number itself.
@end defun

@c page
@node r6rs lexer makers special
@subsubsection Special token makers


The following bindings are exported by the library @library{nausicaa
r6rs lexeme-processing}.


@defun make-string-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Set to a function returning a @class{lexical-token} record representing
a string.  The category is set to the symbol @code{STRING}; the semantic
value is set to the string itself.
@end defun


@defun make-nested-comment-token @var{yygetc} @var{yyungetc} @var{yytext} @var{yyline} @var{yycolumn} @var{yyoffset}
Set to a function returning a @class{lexical-token} record representing
a nested comment.  The category is set to the symbol
@code{NESTED-COMMENT}; the semantic value is set to the string
representing the nested comment.
@end defun

@c page
@node r6rs lexer strings
@subsection Reading strings


@cindex Reading Scheme strings
@cindex Lexer, Scheme strings
@cindex Scheme strings, reading
@cindex Scheme strings, lexer
@cindex Strings in Scheme, lexer
@cindex Strings in Scheme, reader


The following bindings are exported by the @library{nausicaa r6rs lexer}
library.


@defvr Constant r6rs-string-lexer-table
A lexer table to read @rnrs{6} compliant Scheme strings.  This table
needs an input system configured with @code{(counters: 'all)}.  A lexer
thunk using this table must be invoked after the opening double quote of
the string has been consumed from the input system.  See the
documentation of @func{read-string} for a usage example.  A lexer thunk
using this table returns:

@itemize
@item
Scheme characters read from the input system.

@item
Scheme strings read from the input system.

@item
The symbol @code{STRING} when a double quote is read from the input
system.  This symbol signals that the string is finished, we may want to
continue reading with a different lexer thunk.

@item
The return value of the function referenced by the parameter
@func{eoi-token-maker} when the end of input is found.

@item
The return value of the function referenced by the parameter
@func{lexical-error-token-maker} when a lexical error is detected in the
input system.
@end itemize
@end defvr


@defun read-string @var{IS}
Given an input system from which a double quote character has already
been consumed, read characters composing an @rnrs{6} string stopping at
the ending double quote; return the Scheme string.  This function
expects the default functions to be in the parameters of
@library{nausicaa r6rs lexeme-processing}.

If an error occurs reading the string: a condition object is raised with
components @condition{lexical}, @condition{message}, @condition{who},
@condition{irritants}; the single value in the @condition{irritants}
list is the string that caused the error.

If end of input is found reading the string: a condition object is
raised with components @condition{lexical}, @condition{message},
@condition{who}, @condition{irritants}; the single value in the
@condition{irritants} list is the end--of--file object.

The implementation of this function is a useful example of usage for
@code{r6rs-string-lexer-table}:

@example
(define (read-string IS)
  (let-values
      (((port getter) (open-string-output-port))
       ((lexer) (lexer-make-lexer r6rs-string-lexer-table IS)))
    (let next (((T <lexical-token>) (lexer)))
      (define (%error message)
        (raise
         (condition (make-lexical-violation)
                    (make-message-condition message)
                    (make-who-condition read-string)
                    (make-irritants-condition (list T.value)))))
      (cond (T.end-of-input?
             (%error "end of input found while reading string"))
            (T.lexer-error?
             (%error "lexical violation while reading string"))
            ((eq? T 'STRING)
             (getter))
            (else
             (display T port)
             (next (lexer)))))))
@end example
@end defun


@defun read-string* @var{IS}
Like @func{read-string} but do not raise exceptions.  Given an input
system from which a double quote character has already been consumed,
read characters composing an @rnrs{6} string stopping at the ending
double quote.  Return the Scheme string.

If an error occurs reading the string: return the return value of the
function referenced by the parameter @func{lexical-error-token-maker},
which must be a @class{lexical-token} having @code{*lexer-error*} as
category.

If the end of input is found reading the string: return the return value
of the function referenced by the parameter @func{eof-token-maker},
which must be a @class{lexical-token} having @code{*eoi*} as category.
@end defun

@c page
@node r6rs lexer characters
@subsection Reading characters


@cindex Reading Scheme characters
@cindex Lexer, Scheme characters
@cindex Scheme characters, reading
@cindex Scheme characters, lexer
@cindex Characters in Scheme, lexer
@cindex Characters in Scheme, reader


The following bindings are exported by the @library{nausicaa r6rs lexer}
library.


@defvr Constant r6rs-character-lexer-table
A lexer table to read @rnrs{6} compliant Scheme characters.  This table
needs an input system configured with @code{(counters: 'all)}.  See the
documentation of @func{read-character} for a usage example.  A lexer
thunk using this table returns:

@itemize
@item
Scheme characters read from the input system.

@item
The return value of the function referenced by the parameter
@func{eoi-token-maker} when the end of input is found.

@item
The return value of the function referenced by the parameter
@func{lexical-error-token-maker} when a lexical error is detected in the
input system.
@end itemize
@end defvr


@defun read-character @var{IS}
Given an input system, read a single character datum compliant with
@rnrs{6}; return the Scheme character.  This function expects the
default functions to be in the parameters of @library{nausicaa r6rs
lexeme-processing}.

If an error occurs reading the character: a condition object is raised
with components @condition{lexical}, @condition{message},
@condition{who}, @condition{irritants}; the single value in the
@condition{irritants} list is the string that caused the error.

If end of input is found reading the character: a condition object is
raised with components @condition{lexical}, @condition{message},
@condition{who}, @condition{irritants}.  The single value in the
@condition{irritants} list is the end--of--file object.

The implementation of this function is a useful example of usage for
@code{r6rs-character-lexer-table}:

@example
(define (read-character IS)
  (let (((T <lexical-token>)
        ((lexer-make-lexer r6rs-character-lexer-table IS))))
    (define (%error message)
      (raise
       (condition (make-lexical-violation)
                  (make-message-condition message)
                  (make-who-condition 'read-string)
                  (make-irritants-condition (list T.value)))))
    (cond (T.end-of-input?
           (%error
            "end of input found while reading character"))
          (T.lexer-error?
           (%error
            "lexical violation while reading character"))
          (else T))))
@end example
@end defun

@c page
@node r6rs lexer identifiers
@subsection Reading identifiers


@cindex Reading Scheme identifiers
@cindex Lexer, Scheme identifiers
@cindex Scheme identifiers, reading
@cindex Scheme identifiers, lexer
@cindex Identifiers in Scheme, lexer
@cindex Identifiers in Scheme, reader


The following bindings are exported by the @library{nausicaa r6rs lexer}
library.


@defvr Constant r6rs-identifier-lexer-table
A lexer table to read @rnrs{6} compliant Scheme identifiers.  This table
needs an input system configured with @code{(counters: 'all)}.  See the
documentation of @func{read-identifier} for a usage example.  A lexer
thunk using this table returns:

@itemize
@item
Scheme strings read from the input system representing identifiers.

@item
The return value of the function referenced by the parameter
@func{eoi-token-maker} when the end of input is found.

@item
The return value of the function referenced by the parameter
@func{lexical-error-token-maker} when a lexical error is detected in the
input system.
@end itemize
@end defvr


@defun read-identifier @var{IS}
Given an input system, read a single identifier datum compliant with
@rnrs{6}; return the identifier as a Scheme string.  This function
expects the default functions to be in the parameters of
@library{nausicaa r6rs lexeme-processing}.

If an error occurs reading the identifier: a condition object is raised
with components @condition{lexical}, @condition{message},
@condition{who}, @condition{irritants}; the single value in the
@condition{irritants} list is the string that caused the error.

If end of input is found reading the identifier: a condition object is
raised with components @condition{lexical}, @condition{message},
@condition{who}, @condition{irritants}.  The single value in the
@condition{irritants} list is the end--of--file object.

The implementation of this function is a useful example of usage for
@code{r6rs-identifier-lexer-table}:

@example
(define (read-identifier IS)
  (let (((T <lexical-token>)
        ((lexer-make-lexer r6rs-identifier-lexer-table IS))))
    (define (%error message)
      (raise
       (condition (make-lexical-violation)
                  (make-message-condition message)
                  (make-who-condition 'read-identifier)
                  (make-irritants-condition (list T.value)))))
    (cond (T.end-of-input?
           (%error
            "end of input found while reading identifier"))
          (T.lexer-error?
           (%error
            "lexical violation while reading identifier"))
          (else T))))
@end example
@end defun

@c page
@node r6rs lexer numbers
@subsection Reading numbers


@cindex Reading Scheme numbers
@cindex Lexer, Scheme numbers
@cindex Scheme numbers, reading
@cindex Scheme numbers, lexer
@cindex Numbers in Scheme, lexer
@cindex Numbers in Scheme, reader


The following bindings are exported by the @library{nausicaa r6rs lexer}
library.


@defvr Constant r6rs-number-lexer-table
A lexer table to read @rnrs{6} compliant Scheme numbers.  This table
needs an input system configured with @code{(counters: 'all)}.  See the
documentation of @func{read-number} for a usage example.  A lexer thunk
using this table returns:

@itemize
@item
Scheme numbers read from the input system.

@item
The return value of the function referenced by the parameter
@func{eoi-token-maker} when the end of input is found.

@item
The return value of the function referenced by the parameter
@func{lexical-error-token-maker} when a lexical error is detected in the
input system.
@end itemize
@end defvr


@defun read-number @var{IS}
Given an input system, read a single number datum compliant with
@rnrs{6}; return the Scheme number.  This function expects the default
functions to be in the parameters of @library{nausicaa r6rs
lexeme-processing}.

If an error occurs reading the number: a condition object is raised with
components @condition{lexical}, @condition{message}, @condition{who},
@condition{irritants}; the single value in the @condition{irritants}
list is the string that caused the error.

If end of input is found reading the number: a condition object is
raised with components @condition{lexical}, @condition{message},
@condition{who}, @condition{irritants}.  The single value in the
@condition{irritants} list is the end--of--file object.

The implementation of this function is a useful example of usage for
@code{r6rs-number-lexer-table}:

@example
(define (read-number IS)
  (let (((T <lexical-token>)
        ((lexer-make-lexer r6rs-number-lexer-table IS))))
    (define (%error message)
      (raise
       (condition (make-lexical-violation)
                  (make-message-condition message)
                  (make-who-condition 'read-number)
                  (make-irritants-condition (list T.value)))))
    (cond (T.end-of-input?
           (%error
            "end of input found while reading number"))
          (T.lexer-error?
           (%error
            "lexical violation while reading number"))
          (else T))))
@end example
@end defun

@c page
@node r6rs lexer nested comments
@subsection Reading nested comments


@cindex Reading Scheme nested comments
@cindex Lexer, Scheme nested comments
@cindex Scheme nested comments, reading
@cindex Scheme nested comments, lexer
@cindex Nested comments in Scheme, lexer
@cindex Nested comments in Scheme, reader


The following bindings are exported by the @library{nausicaa r6rs lexer}
library.


@defvr Constant r6rs-nested-comment-lexer-table
A lexer table to read @rnrs{6} compliant nested comments of the form
@code{#| ... |#}.  This table needs an input system configured with
@code{(counters: 'all)}.  See the documentation of
@func{read-nested-comment} for a usage example.  A lexer thunk using
this table returns:

@itemize
@item
The symbol @code{OPEN} when the sequence @samp{#|} is read from the
input system.

@item
The symbol @code{CLOSE} when the sequence @samp{|#} is read from the
input system.

@item
The single character value read from the input system.

@item
The return value of the function referenced by the parameter
@func{eoi-token-maker} when the end of input is found.

@item
The return value of the function referenced by the parameter
@func{lexical-error-token-maker} when a lexical error is detected in the
input system.
@end itemize
@end defvr


@defun read-nested-comment @var{IS}
Given an input system from which the opening sequence of nested comments
@samp{#|} has already been consumed, read characters composing an
@rnrs{6} nested comment matching sequence @samp{|#}.  Return the comment
as Scheme string enclosed in @samp{#|} and @samp{|#} sequences.  This
function expects the default functions to be in the parameters of
@library{nausicaa r6rs lexeme-processing}.

If an error occurs reading the nested comment: a condition object is
raised with components @condition{lexical}, @condition{message},
@condition{who}, @condition{irritants}; the single value in the
@condition{irritants} list is the string that caused the error.  Notice
that this should never happen.

If end of input is found reading the nested comment: a condition object
is raised with components @condition{lexical}, @condition{message},
@condition{who}, @condition{irritants}.  The single value in the
@condition{irritants} list is the end--of--file object.

The implementation of this function is a useful example of usage for
@code{r6rs-nested-comment-lexer-table}:

@example
(define (read-nested-comment IS)
  (let-values
      (((port getter) (open-string-output-port))
       ((lexer) (lexer-make-lexer
                   r6rs-nested-comment-lexer-table IS))
       ((count) 1))
    (display "#|" port)
    (let next (((T <lexical-token>) (lexer)))
      (define (%error message)
        (raise
         (condition (make-lexical-violation)
                    (make-message-condition message)
                    (make-who-condition 'read-nested-comment)
                    (make-irritants-condition (list T.value)))))
      (cond (T.end-of-input?
             (%error
              "end of input found while reading nested comment"))
            (T.lexer-error? ;this should never happen
             (%error
              "lexical violation while reading nested comment"))
            ((eq? T 'CLOSE)
             (decr! count)
             (display "|#" port)
             (if (zero? count)
                 (getter)
               (next (lexer))))
            ((eq? T 'OPEN)
             (incr! count)
             (display "#|" port)
             (next (lexer)))
            (else
             (display T port)
             (next (lexer)))))))
@end example
@end defun


@defun read-nested-comment* @var{IS}
Like @func{read-nested-comment} but do not raise exceptions.  Given an
input system from which the opening sequence of nested comments
@samp{#|} has already been consumed, read characters composing an
@rnrs{6} nested comment matching sequence @samp{|#}.  Return the comment
as Scheme string enclosed in @samp{#|} and @samp{|#} sequences.

If an error occurs reading the comment: return the return value of the
function referenced by the parameter @func{lexical-error-token-maker},
which must be a @class{lexical-token} having @code{*lexer-error*} as
category.

If the end of input is found reading the comment: return the return
value of the function referenced by the parameter
@func{eof-token-maker}, which must be a @class{lexical-token} having
@code{*eoi*} as category.
@end defun

@c page
@node r6rs lexer line comments
@subsection Reading line comments


@cindex Reading Scheme line comments
@cindex Lexer, Scheme line comments
@cindex Scheme line comments, reading
@cindex Scheme line comments, lexer
@cindex Line comments in Scheme, lexer
@cindex Line comments in Scheme, reader


The following bindings are exported by the @library{nausicaa r6rs lexer}
library.


@defvr Constant r6rs-line-comment-lexer-table
A lexer table to read @rnrs{6} compliant line comments.  Both comments
with end--of--line and comments spanning until the end--of--input are
accepted.  This table needs an input system configured with
@code{(counters: 'all)}.  See the documentation of
@func{read-line-comment} for a usage example.  A lexer thunk using this
table returns:

@itemize
@item
The comment as a string.

@item
The return value of the function referenced by the parameter
@func{eoi-token-maker} when the end of input is found.

@item
The return value of the function referenced by the parameter
@func{lexical-error-token-maker} when a lexical error is detected in the
input system.
@end itemize
@end defvr


@defun read-line-comment @var{IS}
Given an input system, read characters composing an @rnrs{6} line
comment; return the string representing the comment.  This function
expects the default functions to be in the parameters of
@library{nausicaa r6rs lexeme-processing}.

If an error occurs reading the line comment: a condition object is
raised with components @condition{lexical}, @condition{message},
@condition{who}, @condition{irritants}; the single value in the
@condition{irritants} list is the string that caused the error.

If end of input is found reading the line comment: a condition object is
raised with components @condition{lexical}, @condition{message},
@condition{who}, @condition{irritants}.  The single value in the
@condition{irritants} list is the end--of--file object.

The implementation of this function is a useful example of usage for
@code{r6rs-line-comment-lexer-table}:

@example
(define (read-line-comment IS)
  (let (((T <lexical-token>)
        ((lexer-make-lexer r6rs-line-comment-lexer-table IS))))
    (define (%error message)
      (raise
       (condition (make-lexical-violation)
                  (make-message-condition message)
                  (make-who-condition 'read-line-comment)
                  (make-irritants-condition (list T.value)))))
    (cond (T.end-of-input?
           (%error
            "end of input found while reading line comment"))
          (T.lexer-error?
           (%error
           "lexical violation while reading line comment"))
          (else T))))
@end example
@end defun

@c page
@node r6rs fixed-strings
@section A collection of common strings


The library @library{nausicaa r6rs fixed-strings} exports bindings to
common strings which are meant to be comparable using @func{eq?}.

@c ------------------------------------------------------------

@subsubheading Scheme source strings

@defun comma-at
Bound to the string @samp{",@@"}.
@end defun


@defun sharp-paren
Bound to the string @samp{"#("}.
@end defun


@defun sharp-vu8-paren
Bound to the string @samp{"#vu8("}.
@end defun


@defun sharp-tick
Bound to the string @samp{"#'"}.
@end defun


@defun sharp-back-tick
Bound to the string @samp{"#`"}.
@end defun


@defun sharp-comma-at
Bound to the string @samp{"#,@@"}.
@end defun


@defun sharp-comma-
Bound to the string @samp{"#,"}.
@end defun


@defun sharp-semicolon
Bound to the string @samp{"#;"}.
@end defun


@defun sharp-bang-r6rs
Bound to the string @samp{"#!r6rs"}.
@end defun


@defun sharp-bang
Bound to the string @samp{"#!"}.
@end defun


@defun open-nested-comment
Bound to the string @samp{"#|"}.
@end defun


@defun true-small
Bound to the string @samp{"#t"}.
@end defun


@defun true-capital
Bound to the string @samp{"#T"}.
@end defun


@defun false-small
Bound to the string @samp{"#f"}.
@end defun


@defun false-capital
Bound to the string @samp{"#F"}.
@end defun

@c ------------------------------------------------------------

@subsubheading Named character strings

@defun named-character-nul
Bound to the string @samp{"#\\nul"}.
@end defun


@defun named-character-alarm
Bound to the string @samp{"#\\alarm"}.
@end defun


@defun named-character-backspace
Bound to the string @samp{"#\\backspace"}.
@end defun


@defun named-character-tab
Bound to the string @samp{"#\\tab"}.
@end defun


@defun named-character-linefeed
Bound to the string @samp{"#\\linefeed"}.
@end defun


@defun named-character-newline
Bound to the string @samp{"#\\newline"}.
@end defun


@defun named-character-vtab
Bound to the string @samp{"#\\vtab"}.
@end defun


@defun named-character-page
Bound to the string @samp{"#\\page"}.
@end defun


@defun named-character-return
Bound to the string @samp{"#\\return"}.
@end defun


@defun named-character-esc
Bound to the string @samp{"#\\esc"}.
@end defun


@defun named-character-space
Bound to the string @samp{"#\\space"}.
@end defun


@defun named-character-delete
Bound to the string @samp{"#\\delete")}.
@end defun

@c end of file
