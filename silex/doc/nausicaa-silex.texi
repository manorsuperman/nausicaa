\input texinfo.tex
@c %**start of header
@setfilename nausicaa-silex.info
@settitle SILex
@c %**end of header

@c page
@c ------------------------------------------------------------
@c Macros.
@c ------------------------------------------------------------

@include version.texiinc

@c ------------------------------------------------------------
@c License macros.
@c ------------------------------------------------------------

@macro gnu{}
@acronym{GNU}
@end macro

@macro gpl{}
@acronym{GPL}
@end macro

@macro fdl{}
@acronym{FDL}
@end macro

@macro bsd{}
@acronym{BSD}
@end macro

@c ------------------------------------------------------------
@c Miscellaneous acronyms.
@c ------------------------------------------------------------

@macro ansi{}
@acronym{ANSI}
@end macro

@macro api{}
@acronym{API}
@end macro

@macro ascii{}
@acronym{ASCII}
@end macro

@macro cpu{}
@acronym{CPU}
@end macro

@macro ieee{}
@acronym{IEEE}
@end macro

@macro iso{}
@acronym{ISO}
@end macro

@macro ram{}
@acronym{RAM}
@end macro

@macro posix{}
@acronym{POSIX}
@end macro

@c Remember that @url is already used by Texinfo.
@macro urla{}
@acronym{URL}
@end macro

@macro utf{}
@acronym{UTF}
@end macro

@c ------------------------------------------------------------
@c Software related macros.
@c ------------------------------------------------------------

@macro gmp{}
@acronym{GMP}
@end macro

@macro gcc{}
@acronym{GCC}
@end macro

@macro glibc{}
@gnu{} C Library
@end macro

@c ------------------------------------------------------------
@c Network related acronyms.
@c ------------------------------------------------------------

@macro tcp{}
@acronym{TCP}
@end macro

@macro udp{}
@acronym{UDP}
@end macro

@macro icmp{}
@acronym{ICMP}
@end macro

@c ------------------------------------------------------------

@macro http{}
@acronym{HTTP}
@end macro

@macro https{}
@acronym{HTTP}
@end macro

@macro ftp{}
@acronym{FTP}
@end macro

@macro smtp{}
@acronym{SMTP}
@end macro

@macro snmp{}
@acronym{SNMP}
@end macro

@c ------------------------------------------------------------
@c Arguments macros.
@c ------------------------------------------------------------

@macro vari{ARG}
@var{\ARG\1}
@end macro

@macro varii{ARG}
@var{\ARG\2}
@end macro

@macro variii{ARG}
@var{\ARG\3}
@end macro

@macro variv{ARG}
@var{\ARG\4}
@end macro

@macro varn{ARG}
@var{\ARG\n}
@end macro

@macro vark{ARG}
@var{\ARG\k}
@end macro

@macro varj{ARG}
@var{\ARG\j}
@end macro

@c ------------------------------------------------------------

@macro meta{ARG}
<\ARG\>
@end macro

@macro metai{ARG}
@meta{\ARG\1}
@end macro

@macro metaii{ARG}
@meta{\ARG\2}
@end macro

@macro metaiii{ARG}
@meta{\ARG\3}
@end macro

@macro metaiv{ARG}
@meta{\ARG\4}
@end macro

@macro metan{ARG}
@meta{\ARG\n}
@end macro

@macro metak{ARG}
@meta{\ARG\k}
@end macro

@macro metaj{ARG}
@meta{\ARG\j}
@end macro

@c ------------------------------------------------------------
@c C language macros.
@c ------------------------------------------------------------

@macro cfunc{NAME}
@code{\NAME\()}
@end macro

@macro cnull{}
@code{NULL}
@end macro

@c ------------------------------------------------------------
@c Scheme language macros.
@c ------------------------------------------------------------

@macro clos{}
@acronym{CLOS}
@end macro

@macro library{NAME}
@code{(\NAME\)}
@end macro

@macro repl{}
@acronym{REPL}
@end macro

@macro rnrs{VERSION}
@acronym{R\VERSION\RS}
@end macro

@macro srfi{}
@acronym{SRFI}
@end macro

@ignore
Separating the @srfi{}  macro from the number with a  '--' rather than a
'-' makes the expansion look ugly in menu entries under the Info reader.
IMHO this should not happen, but  it does; so we live with this, because
the main purpose of this document is to provide an Info version.
@end ignore
@macro ansrfi{NUM}
@srfi{}-\NUM\
@end macro

@c ------------------------------------------------------------

@macro func{NAME}
@code{@sc{\NAME\}}
@end macro

@macro nil{}
@code{()}
@end macro

@macro true{}
@code{#t}
@end macro

@macro false{}
@code{#f}
@end macro

@macro keyword{NAME}
@code{#:\NAME\}
@end macro

@macro class{NAME}
@code{<\NAME\>}
@end macro

@c ------------------------------------------------------------
@c Macros for references to external documents.
@c ------------------------------------------------------------

@macro glibcref{NODE, TITLE}
@ref{\NODE\,\TITLE\,\TITLE\,libc}
@end macro

@macro rsixref{NODE, TITLE}
@ref{\NODE\,\TITLE\,\TITLE\,r6rs}
@end macro

@macro rfiveref{NODE, TITLE}
@ref{\NODE\,\TITLE\,\TITLE\,r5rs}
@end macro

@macro ikarusref{NODE, TITLE}
@ref{\NODE\,\TITLE\,\TITLE\,ikarus}
@end macro

@macro urielref{NODE, TITLE}
@ref{\NODE\,\TITLE\,\TITLE\,nausicaa-uriel}
@end macro

@macro bibref{TAG}
@code{[\TAG\]}
@end macro

@c page
@c ------------------------------------------------------------
@c Values.
@c ------------------------------------------------------------

@set TITLE                      SILex

@c To be used as @value{PACKAGE} whenever we need to include the full
@c name of this package.
@set PACKAGE                    Nausicaa/SILex

@c To be used as @value{PACKAGE} whenever we need to include the
@c nickname of the project: the name that is used to compose the
@c distribution tarball or the web address.
@set PACKAGE_NICKNAME           nausicaa-silex

@c To be used as @value{AUTHOR} whenever we need to include the list of
@c authors of this document.
@set AUTHOR                     Danny Dube'

@c To be used as @value{AUTHOR_EMAIL} whenever we need to include the
@c email of the *single* author of this document.
@set AUTHOR_EMAIL               @email{dube@@iro.umontreal.ca}

@c To be used as @value{COPYRIGHT_YEARS} whenever we need to include the
@c list of copyright years.
@set COPYRIGHT_YEARS            2001, 2009

@c page
@c ------------------------------------------------------------
@c Copyright notice.
@c ------------------------------------------------------------

@copying
@noindent
This document describes version @version{} of @value{PACKAGE}, SILex is
a lexical analyser generator with a Lex--like syntax.  It is a port to
@rnrs{6} Scheme of SILex version 1.0.

The package is distributed under the terms of the @gnu{} General Public
License (@gpl{}) as part of the Nausicaa distribution; it can be
downloaded from:

@center @url{http://github.com/marcomaggi/nausicaa/tree/master}

@noindent
Copyright @copyright{} @value{COPYRIGHT_YEARS} by @value{AUTHOR} @value{AUTHOR_EMAIL}@*
Port to @rnrs{6} Scheme and Nausicaa integration by Marco Maggi @email{marcomaggi@@gna.org}.

@quotation
Permission is granted to copy, distribute and/or modify this document
under the terms of the @gnu{} Free Documentation License, Version 1.2 or
any later version published by the Free Software Foundation; with
Invariant Sections being ``@gnu{} Free Documentation License'' and
``@gnu{} General Public License'', no Front--Cover Texts, and no
Back--Cover Texts.  A copy of the license is included in the section
entitled ``@gnu{} Free Documentation License''.
@end quotation
@end copying

@c page
@c ------------------------------------------------------------
@c Headers.
@c ------------------------------------------------------------

@titlepage
@title @value{TITLE}
@subtitle Revision @version{}
@author @value{AUTHOR} @value{AUTHOR_EMAIL}
@page
@vskip 0pt plus 1filll
@insertcopying
@end titlepage

@c ------------------------------------------------------------

@ifinfo
@dircategory Development
@direntry
* nausicaa-silex: (nausicaa-silex).     A lexical analyser generator
                                        with a Lex-like syntax.
@end direntry
@end ifinfo

@c ------------------------------------------------------------

@ignore
@syncodeindex tp cp
@syncodeindex vr cp
@syncodeindex fn cp
@end ignore

@c page
@ifnottex
@node Top
@top @value{TITLE}

@insertcopying

@menu
* overview::                    Overview of the package.
* syntax::                      Syntax of the specification file.
* semantics::                   Semantics of the specification file.
* using::                       Generating and using a lexical analyser.

Appendices

* lalr::                        Interfacing with an @sc{lalr}(1) parser.
* ack::                         Acknowledgements
* Package License::             GNU General Public License.
* Documentation License::       GNU Free Documentation License.
* references::                  Bibliography and references.

Indexes

* concept index::               An entry for each concept.
* function index::              An entry for each function.
* variable index::              An entry for each variable.
* type index::                  An entry for each type.

@detailmenu
 --- The Detailed Node Listing ---

Syntax of the specification file

* syntax macros::               Syntax of the macro definitions.
* syntax rules::                Syntax of the rule--action pairs.
* syntax regexp::               How to build regular expressions.
* syntax sample::               Show some frequent mistakes.

Regular expressions

* syntax regexp atomic::        Atomic regular expressions.
* syntax regexp compose::       Composing regular expressions.
* syntax regexp marker::        Markers.
* syntax regexp space::         White spaces in regular expressions.

Semantics of the specification file

* semantics action::            What does an action.
* semantics rules::             When does a regular expression
                                matches the input.

Generating and using a lexical analyser

* using one::                   Generating and using one
                                complete analyser.
* using many::                  Dynamic creation of analysers.
* using options::               Line counting, table encoding.
* using input::                 Input from a port, a string or
                                a function.

One complete analyser

* using one lex::               The @func{lex} command.
* using one functions::         The functions in the lexical analyser.
* using one usage::             Using the lexical analyser.

Many analysers

* using many style::            It is possible to parse many files
                                with many analysers.
* using many tables::           The @func{lex-tables} procedure.
* using many usage::            Building and using lexical analysers
                                dynamically.

Options at generation time

* using options counters::      Keeping the position in the input.
* using options tables::        Encodings of the tables of an
                                analyser.
* using options print::         Pretty printing the tables.

@end detailmenu
@end menu

@end ifnottex

@c page
@node overview
@chapter Overview of the package


This document describes @value{PACKAGE}.  ``SILex'' stands for ``Scheme
Implementation of Lex''.  It generates a Scheme lexical analyser from a
Lex--like specification file.

SILex has many similarities with the C programs, but has many
differences, too.  The syntax of the specification files for SILex is
close to that of Lex and Flex.  Of course, the actions must be written
in Scheme and not in C.  The set of regular expressions is mostly the
same.  An important difference is relative to the multiple start states
in the C analysers.  SILex replaces them by allowing multiple analysers
to take their input from the same source.  Different inputs can be
analysed at the same time, possibly with different instances of one or
more lexical analysers.  The analysers are created dynamically.

SILex provides many other features.  The designer of a lexical analyser
can specify the actions to be taken when the end of file is reached or
when an error occurs.  The analyser can keep track of the position in
the input in terms of the number of the line, column and offset.  An
analyser can take its input from an input port, a string or a function.
SILex is portable; it does not depend on a particular character set.  It
can generate analysers that are portable, too.

Finally, the table encoding the behavior of the analyser can be compiled
to Scheme code.  The fastest lexical analysers can be produced this way.

@c page
@node syntax
@chapter Syntax of the specification file


@cindex Syntax of the specification file
@cindex Specification file
@cindex Comment
@cindex White space


A specification file for a lexical analyser contains two parts: the
@dfn{macro definitions part} and the @dfn{rules part}.  The two parts
are separated by the mark @code{%%}.  The first part is used to define
@dfn{macros}; that is, to give names to some regular expressions.  The
second part is used to indicate the regular expressions with which the
input will have to match and the @dfn{actions} associated with each
expression.

Comments can be inserted any place where white space is allowed and is
considered as white space itself.  The syntax of the comments is the
same as in Scheme.  That is, it begins with a semicolon @samp{;} and
extends up to the end of a line.  The semicolon is a valid token in many
languages, so you should take care not to comment out an entire line
when you write a regular expression matching a semicolon.

The syntax of each part is presented, except for the regular
expressions, which are described apart.

@menu
* syntax macros::               Syntax of the macro definitions.
* syntax rules::                Syntax of the rule--action pairs.
* syntax regexp::               How to build regular expressions.
* syntax sample::               Show some frequent mistakes.
@end menu

@c page
@node syntax macros
@section Macro definitions part


@cindex Macro
@cindex Macro definitions part
@cindex Scope of a macro definition


The first part of a specification file contains zero or more macro
definitions.  A definition consists of a name and a regular expression,
separated by white space.  It looks better when each definition is
written on a separate line.

The syntax for a macro name is that of a Scheme symbol.  The case of the
letters is not significant.  For example, @code{abcd}, @code{+},
@code{...}, @code{Digit} and @code{digit} are all valid macro names; the
last two being the same.  We cannot write two macro definitions with the
same name.

The defined macro can be referenced in regular expressions using the
syntax @code{@{@var{name}@}} (@pxref{syntax regexp, Regular
expressions}).  The scope of a macro definition includes the remaining
definitions and the rules part of the file.  It is analogous to the
@code{let*} is Scheme, where the macro definitions correspond to the
bindings and the rules part correspond to the body.

We end the macro definitions part with @code{%%}.

@c page
@node syntax rules
@section Rules part


@cindex Rules part
@cindex Pattern
@cindex Action
@cindex Indentation in actions


The rules part contains the rules up to the end of the specification
file.  Each rule is a @dfn{pattern} optionally followed by an
@dfn{action}.  The pattern is a regular expression.  The action, if
there is one, is formed of one or more Scheme expressions.

The actions can span over several lines.  To distinguish between the
remaining of the current action and the start of a new rule, SILex
checks the indentation.  A new rule must start at the beginning of the
line.  That is, the action starts right after the pattern and contains
all the following lines that start with white space.

SILex does not parse the actions.  It simply captures the text
up to the start of the next rule.  So a syntax error in an action is not
detected by SILex.

Nevertheless, SILex is able to detect that an action has been omitted.
In that case, a default action is supplied.

@c page
@node syntax regexp
@section Regular expressions


We first describe the atomic regular expressions.  Then, we show how to
build more complex regular expressions from simpler ones.  Finally, the
markers are introduced.

@menu
* syntax regexp atomic::        Atomic regular expressions.
* syntax regexp compose::       Composing regular expressions.
* syntax regexp marker::        Markers.
* syntax regexp space::         White spaces in regular expressions.
@end menu

@c page
@node syntax regexp atomic
@subsection Atomic regular expressions


@cindex Regular expression
@cindex Atomic regular expression
@cindex Ordinary character
@cindex Dot
@cindex Wild card
@findex .
@cindex Backslash
@cindex Protecting a character
@findex \n
@findex \@var{integer}
@findex \@var{c}
@cindex Macro reference
@findex @{@var{name}@}
@cindex String
@findex "@var{some text}"
@cindex Character class
@findex [@var{list of characters}]


The following constructs are regular expressions:

@table @code
@item c
@dfn{Ordinary character}.  It is a regular expression that matches the
character @var{c} itself.  @var{c} cannot be one of @samp{.}, @samp{\},
@samp{@{}, @samp{"}, @samp{[}, @samp{|}, @samp{?}, @samp{+}, @samp{*},
@samp{(}, @samp{)}, @samp{^}, @samp{$}, @samp{;} or any white space.

@item .
@dfn{Wild card}.  It matches any character except the newline character.

@item \n
@itemx \@var{integer}
@itemx \@var{c}
@dfn{Backslash}.  The backslash is used for two things: protect a
character from special meaning; generating non-printable characters.
The expression @code{\n} matches the newline character.  The expression
@code{\@var{integer}} matches the character that has number
@var{integer} (in the sense of @func{char->integer}).  @var{integer}
must be a valid character number on the underlying Scheme
implementation.  The expression @code{\@var{c}} matches the character
@var{c} if @var{c} is not @samp{n}, @samp{-} nor a digit.

@item @{@var{name}@}
@dfn{Macro reference}.  This expression matches the same lexemes as
those matched by the regular expression named @var{name}.  We can
imagine that the reference is replaced by the text of the named
expression.  However, it works as if parentheses had been added to
protect the substituting expression.

@item "@var{some text}"
@dfn{String}.  A string matches a lexeme identical to its contents.  In
a string, the only special characters are @samp{"}, which closes the
string, and @samp{\} which keeps the effect mentioned above.

@item [@var{list of characters}]
@itemx []@var{list of characters}]
@itemx [-@var{list of characters}]
@itemx [^@var{list of characters}]
@dfn{Character class}.  The expression matches one of the enumerated
characters.  For example, the expression @samp{[abc]} matches one of
@samp{a}, @samp{b} and @samp{c}.

We can list a range of characters by writing the first character, the
@samp{-} and the last character.  For example, @samp{[A-Za-z]} matches
one letter.

The special characters in a class are @samp{]}, which closes the class,
@samp{-}, which denotes a range of character, and @samp{\}, which keeps
its usual meaning.

There is an exception with the first character in a class.  If the first
character is @samp{]} or @samp{-}, it loses its special meaning.  If the
first character is @samp{^}, the expression matches one character if it
is @strong{not} enumerated in @var{list of characters}.
@end table

@c page
@node syntax regexp compose
@subsection Composing regular expressions


@cindex Union of regular expressions
@cindex Alternatives
@findex |
@cindex Concatenation of regular expressions
@cindex Optional regular expression
@findex ?
@cindex Closure of a regular expression
@cindex Positive closure
@findex +
@cindex Kleene closure
@findex *
@cindex Repetition of a regular expression
@findex @{@var{i},@var{j}@}
@cindex Overriding the precedence
@cindex Grouping regular expressions
@cindex Precedence
@findex ( )


Suppose @var{r} and @var{s} are regular expressions.  Then the following
expressions can be built:

@table @code
@item @var{r}|@var{s}
@dfn{Union}.  This regular expression matches a lexeme if the lexeme is
matched by @var{r} or by @var{s}.

@item @var{r}@var{s}
@dfn{Concatenation}.  This expression matches a lexeme if the lexeme can
be written as the concatenation of a lexeme matched by @var{r} and a
lexeme matched by @var{s}.

@item @var{r}?
@dfn{Optional expression}.  A lexeme matches this expression if it is
the empty lexeme or if it matches @var{r}.

@item @var{r}+
@dfn{Positive closure}.  This expression matches a lexeme that can be
written as the concatenation of one or more lexemes, where each of those
matches @var{r}.

@item @var{r}*
@dfn{Kleene closure}.  A lexeme is matched by this expression if it can
be written as the concatenation of zero or more lexemes, where each of
those matches @var{r}.

@item @var{r}@{@var{i}@}
@itemx @var{r}@{@var{i},@}
@itemx @var{r}@{@var{i},@var{j}@}
@dfn{Power or repetition of an expression}.  These expressions allow the
``repetition'' of a regular expression a certain number of times.
@var{i} and @var{j} must be positive integers and @var{j} must be
greater or equal to @var{i}.

The first form repeats the expression @var{r} exactly @var{i} times.
The second form repeats @var{r} at least @var{i} times.  The last form
repeats @var{r} at least @var{i} times and at most @var{j} times.

We should avoid using large numbers (more than @math{10}), because the
finite automaton for @var{r} is copied once for each repetition.  The
tables of the analyser may quickly become very large.  We should note
that the syntax of these expressions does not conflict with the syntax
of the macro reference.

@item (@var{r})
@dfn{Parentheses}.  This expression matches the same lexemes as @var{r}.
It is used to override the precedence of the operators.
@end table

The building operators are listed in order of increasing precedence.
The @code{?}, @code{+}, @code{*} and repetition operators have the same
precedence.

@c page
@node syntax regexp marker
@subsection Markers


@cindex Marker
@cindex Beginning of line marker
@findex ^
@cindex End of line marker
@findex $
@cindex End of file marker
@findex <<EOF>>
@cindex Error marker
@findex <<ERROR>>


The remaining ``expressions'' would better be called @dfn{markers}.
They all match the empty lexeme but require certain conditions to be
respected in the input.  They cannot be used in all regular expressions.
Suppose that @var{r} is a regular expression without markers.

@table @code
@item ^@var{r}
@itemx @var{r}$
@dfn{Beginning and end of line}.  These markers require that the lexeme
is found at the beginning and at the end of the line, respectively.  The
markers lose their special meaning if they are not placed at their end
of the regular expression or if they are used in the first part of the
specification file.  In those cases, they are treated as regular
characters.

@item <<EOF>>
@dfn{End of file}.  This marker is matched only when the input is at the
end of file.  The marker must be used alone in its pattern, and only in
the second part of the file.  There can be at most one rule with this
particular pattern.

@item <<ERROR>>
@dfn{Error}.  This marker is matched only when there is a parsing error.
It can be used under the same conditions as @code{<<EOF>>}.
@end table

@c page
@node syntax regexp space
@subsection White spaces in regular expressions


@cindex White space in regular expressions

White space ends the regular expressions.  In order to include white
space in a regular expression, it must be protected by a backslash or
placed in a string.

@c page
@node syntax sample
@section An example of a specification file


Here is an example of a SILex specification file.  The file is
syntactically correct from the SILex point of view.  However, many
common mistakes are shown.  The file is not a useful one.

@example
; This is a syntactically correct but silly file.

partial     hel
complete    @{partial@}lo            ; @r{Backward macro ref. only}
digit       [0-9]
letter      [a-zA-Z]

%%

-?@{digit@}+    (cons 'integer yytext)   ; @r{@code{yytext} contains}
                                       ; @r{the lexeme}
-?@{digit@}+\.@{digit@}+[eE][-+]?@{digit@}+
              (cons                ; @r{A long action}
               'float
               yytext)

;             (list 'semicolon)    ; @r{Probably a mistake}

begin         )list 'begin(        ; @r{No error detected here}
end                                ; @r{The action is optional}

\73           (list 'bell-3)       ; @r{It does not match the}
                                   ; @r{char. # 7 followed by @samp{3}}
\0073         (list 'bell-3)       ; @r{Neither does it}
(\7)3         (list 'bell-3)       ; @r{This does it}

"*()+|@{@}[].? are ordinary but \" and \\ are special"

[^\n]         (list 'char)         ; @r{Same thing as @samp{.}}
(@{letter@}|_)(@{letter@}|_|@{digit@})*  ; @r{A C identifier}
[][]                               ; @r{One of the square brackets}

Repe(ti)@{2@}on   (list 'repetition)

^@{letter@}+:   (cons 'label yytext) ; @r{A label placed at the}
                                   ; @r{beginning of the line}
$^                                 ; @r{No special meaning}
<<EOF>>       (list 'eof)          ; @r{Detection of the end of file}
<<ERROR>>     (my-error)           ; @r{Error handling}
@end example

@c page
@node semantics
@chapter Semantics of the specification file


@cindex Semantics of the specification file


An important part of the semantics of a specification file is described
with the syntax of the regular expressions.  The remainder is presented
here.  We begin with the role of the actions.  Information on the
matching method follows.

@menu
* semantics action::            What does an action.
* semantics rules::             When does a regular expression
                                matches the input.
@end menu

@c page
@node semantics action
@section Evaluation of the actions


@findex yycontinue
@findex yygetc
@findex yyungetc
@findex yytext
@findex yyline
@findex yycolumn
@findex yyoffset
@cindex Skipping a lexeme
@cindex Getting characters
@cindex Ungetting characters
@cindex Lexeme
@cindex Line number
@cindex Column number
@cindex Offset
@cindex Default action


The action of a rule is evaluated when the corresponding pattern is
matched.  The result of its evaluation is the result that the lexical
analyser returns to its caller.

There are a few local variables that are accessible by the action when
it is evaluated: @code{yycontinue}, @code{yygetc}, @code{yyungetc},
@code{yytext}, @code{yyline}, @code{yycolumn} and @code{yyoffset}.

@table @code
@item yycontinue
This variable contains the lexical analysis function itself.  Use
@code{(yycontinue)} to ask for the next token.  Typically, the action
associated with a pattern that matches white space is a call to
@code{yycontinue}; it has the effect of skipping the white space.

@item yygetc
@itemx yyungetc
These variables contain functions to get and unget characters from the
input of the analyser.  They take no argument.  @code{yygetc} returns a
character or the symbol @samp{eof} if the end of file is reached.

They should be used to read characters instead of accessing directly the
input port because the analyser may have read more characters in order
to have a look--ahead.

It is incorrect to try to unget more characters than has been gotten
since @emph{the parsing of the last token}.  If such an attempt is made,
@code{yyungetc} silently refuses.

@item yytext
This variable is bound to a string containing the lexeme.  This string
is guaranteed not to be mutated.  The string is created only if the
action @emph{seems} to need it.  The action is considered to need the
lexeme when @samp{yytext} appears somewhere in the text of the action.

@item yyline
@itemx yycolumn
@itemx yyoffset
These variables indicate the position in the input at the beginning of
the lexeme.  @code{yyline} is the number of the line; the first line is
numbered @math{1}.  @code{yycolumn} is the number of the column; the
first column numbered @math{1}.

It is important to mention that characters such as the tabulation
generate a variable length output when they are printed.  So it would be
more accurate to say that @code{yycolumn} is the index of the first
character of the lexeme, starting at the beginning of the line.

@code{yyoffset} indicates the distance from the beginning of the input;
the first lexeme has offset @math{0}.

The three variables may not all be existant depending on the kind of
counting you want the analyser to do for you (@pxref{using options
counters, Line column and offset counters}).
@end table

There is a default action that is provided for a rule when its action is
omitted.

@itemize
@item
If the pattern is @samp{<<EOF>>}, the default action returns
the object @samp{(0)}.

@item
If the pattern is @samp{<<ERROR>>}, the default action displays an error
message and returns the symbol @samp{error}@footnote{Note that there is
no portable way for the analyser to end the execution of the program
when an error occurs.}.

@item
The default action for the other patterns is to call the analyser again.
It is clearer (and normally more useful) to specify explicitly the
action associated with each rule.
@end itemize

@c page
@node semantics rules
@section Matching the rules


@cindex Matching method
@cindex Matching conflict
@cindex Conflict between patterns
@cindex Interactive analyser


Each time the analyser is asked to return a token, it tries to match a
prefix of the input with a pattern.  There may be more than one possible
match; when it is the case, we say there is a conflict.  For example,
suppose we have those regular expressions:

@example
begin
[a-z]*
@end example

@noindent
and the input is @samp{beginning1 @r{@dots{}}}.  We have a match with
the first expression and we have many different matches with the second.
To resolve such a conflict, the longest match is chosen.  So the chosen
match is the one between the lexeme @samp{beginning} and the second
pattern.

Suppose we have the same regular expressions but the input is
@samp{begin+ @r{@dots{}}}.  We have @emph{two} longest match.  This
conflict is resolved by choosing the first pattern that allows a longest
match.  So the chosen match is between the lexeme @samp{begin} and the
first pattern.

The analyser generated by SILex allows the empty lexeme to be matched if
there is no longer match.  However, you should take care not to call the
analyser again without consuming at least one character of the input.
It would cause an infinite loop.

The pattern @samp{<<EOF>>} is matched when the analyser is called and
the input is at end of file.  In this situation, the marker is matched
even if there is a pattern that matches the empty lexeme.  The analyser
can be called again and again and the @samp{<<EOF>>} pattern will be
matched each time, causing its corresponding action to be evaluated each
time, too.

The pattern @samp{<<ERROR>>} is matched when the input is not at end of
file and no other match is possible.  Depending on the action associated
with this pattern, your program may choose to stop or choose to try to
recover from the error.  To recover from the error, your program has to
read some characters from the input before it can call the analyser
again.

All lexical analysers generated by SILex are interactive.  That is, they
read as few characters as possible to get the longest match.  This is a
useful property when the input is coming from a terminal.  A lexical
analyser is normally based on a finite automaton; it is the case for the
analysers generated by SILex.  A non--interactive analyser always needs
an extra character to provoke an invalid transition in the automaton.
The longest match is detected this way.  With an interactive analyser,
an extra character is not required when it is impossible to obtain a
longer match.

A lexical analyser generated by SILex does not impose any @i{a priori}
limit on the size of the lexemes.  The internal buffer is extended each
time it is necessary.

@c page
@node using
@chapter Generating and using a lexical analyser


@cindex Generating a lexical analyser
@cindex Using a lexical analyser


The most common use of SILex is to generate a single complete lexical
analyser.  In some situations however, it is preferable to only generate
the tables describing the analysers and leaving to the program to build
complete analysers at run time.  It is the case when the program has to
parse many files simultaneously with the same analyser; and when a file
is to be parsed using many different analysers.  After the description
of the two modes, we describe the SILex options and the different input
methods.

@menu
* using one::                   Generating and using one
                                complete analyser.
* using many::                  Dynamic creation of analysers.
* using options::               Line counting, table encoding.
* using input::                 Input from a port, a string or
                                a function.
@end menu

@c page
@node using one
@section One complete analyser


The function @func{lex} generates a complete lexical analyser.  We first
describe its parameters.  Then the interface with the generated analyser
is presented.

@menu
* using one lex::               The @func{lex} command.
* using one functions::         The functions in the lexical analyser.
* using one usage::             Using the lexical analyser.
@end menu

@c page
@node using one lex
@subsection The @func{lex} command


@defun lex @var{input-file} @var{output-file} @var{options} @dots{}
@var{input-file} is a string containing the name of the specification
file.  @var{output-file} is a string containing the name of the file in
which the lexical analyser is written.  @ref{using options}, for a
description of the options.
@end defun


This is an example of a call to @func{lex}:

@example
(lex "pascal.l" "pascal.l.scm")
@end example

@c page
@node using one functions
@subsection The functions in the lexical analyser


@findex lexer
@findex lexer-get-line
@findex lexer-get-column
@findex lexer-get-offset
@findex lexer-getc
@findex lexer-ungetc
@findex lexer-init
@cindex Name convention


The file generated by @func{lex} contains few global definitions.  A
program using the analyser needs only the following functions:
@func{lexer}, @func{lexer-get-line}, @func{lexer-get-column},
@func{lexer-get-offset}, @func{lexer-getc}, @func{lexer-ungetc} and
@func{lexer-init}.


@defun lexer
The lexical analysis function.
@end defun


@defun lexer-get-line
@defunx lexer-get-column
@defunx lexer-get-offset
Functions to obtain the current position in the input.
@end defun


@defun lexer-getc
@defunx lexer-ungetc
Reading and returning characters.  These functions have the advantage of
being accessible from outside the actions.
@end defun


@defun lexer-init
Initializing the analyser with the input source.
@end defun


To avoid name conflicts, these variables and others that we did not
mention all begin with @samp{lexer@r{@dots{}}}.

@c page
@node using one usage
@subsection Using the lexical analyser


@cindex Initialization of the analyser
@cindex Token


The first function that must be called is the initialization function.
It is necessary to give to the analyser its source of characters.


@defun lexer-init @var{input-type} @var{input}
The values @var{input-type} and @var{input} are described in @ref{using
input}.
@end defun


Once the initialization is done, the program can get @dfn{tokens} from
the analyser by calling the lexical analysing function:

@example
(lexer)
@end example

@noindent
The token is the result of the evaluation of the action corresponding to
the matched pattern.  The current position can be obtained with:

@example
(lexer-get-line)
(lexer-get-column)
(lexer-get-offset)
@end example

@noindent
As is described in @ref{using options}, some or all of these functions
may not be available.  Characters can be gotten and ungotten from the
input this way:

@example
(lexer-getc)
(lexer-ungetc)
@end example

@noindent
It is important to note that the analyser remembers the characters
previously gotten.  Your program does not have to keep those itself.

Even after the end of file has been reached or an error has occured, the
@func{lexer} function can be called again.  Its behavior depends on the
remaining characters in the input.

The analyser can be reinitialized in any time with a new input.

@c page
@node using many
@section Many analysers


There are applications where it is necessary to have more than one
lexical analyser parsing more than one file at a time.  For example:

@itemize
@item
The parsing of a C file (with @command{cpp}) may cause the parsing of
other files recursively because of the @code{#include} commands.

@item
An interactive compiler has to be able to compile a file without closing
the communication with the standard input.

@item
SILex itself parses the macro names, the regular expressions, the
interior of a string, @dots{}, with different sets of patterns.
@end itemize

We first begin with an overview on how SILex allows the programmer to
create multiple lexical analysers.  We continue with a description of
the function @func{lex-tables}.  We end the explanations with the
functions used to creat analysers dynamically.

@menu
* using many style::            It is possible to parse many files
                                with many analysers.
* using many tables::           The @func{lex-tables} procedure.
* using many usage::            Building and using lexical analysers
                                dynamically.
@end menu

@c page
@node using many style
@subsection Creating analysers dynamically


@cindex Dynamic creation of analysers
@cindex Input system


It is quite easy to create new analysers at run--time.  Suppose there is
an input that you want to analyse.  There are just two steps to make.

@itemize
@item
Create an @dfn{input system} from the input.  An input system provides
the buffering, the line counting and similar low level services.

@item
Create one or more analysers from the input system and the analyser
tables.  The tables are generated by the function @func{lex-tables} from
a specification file.  A table contains all the necessary information to
build up an analyser.  Normally, we have to use more than one analyser
per input when we expect the syntax to vary greatly in the input.
@end itemize

The following example shows a typical organization for a multi--analyser
lexical analysis.  Note that one table may have been used to produce
many instances of analysers.  Those analysers would simply be connected
to different input systems@footnote{It would make no sense to create two
instances coming from the same table and being connected to the same
input system.  They would both have exactly the same behavior.}.

@example
           Input1            Input2        Input3
             |                 |             |
             |                 |             |
            IS1               IS2           IS3
             |                 |             |
     +-------+-------+         |          +--+---+
     |       |       |         |          |      |
   An1.1   An1.2   An1.3     An2.1      An3.1  An3.2
@end example

There is no @i{a priori} limit on the number of input systems and
analysers that we can create dynamically.

@c page
@node using many tables
@subsection The @func{lex-tables} procedure


The function @func{lex-tables} produces a table describing an analyser
from a specification file.


@defun lex-tables @var{input-file} @var{table-name} @var{output-file} @var{options} @dots{}
@var{input-file} must be a string containing the name of the
specification file.  @var{output-file} is a string containing the name
in which the result is printed.  A definition is written in the output
file.  @var{table-name} must be a string and it is the name appearing in
the definition.  The options are defined in @ref{using options}.
@end defun

This is an example of a call to @func{lex-tables}:

@example
(lex-tables "c.l" "c-table" "c.l.scm")
@end example

@c page
@node using many usage
@subsection Building and using lexical analysers dynamically


@cindex Building an analyser dynamically
@pindex multilex.scm
@cindex Name convention
@findex lexer-make-IS
@findex lexer-get-func-line
@findex lexer-get-func-column
@findex lexer-get-func-offset
@findex lexer-get-func-getc
@findex lexer-get-func-ungetc
@findex lexer-make-lexer


In order to be able to create dynamically the analysers the program
needs, the files containing the tables and the file @file{multilex.scm}
must be loaded as part of the program.  The name convention is the
following: All definitions in @file{multilex.scm} introduce names
beginning with @samp{lexer@r{@dots{}}} and the definitions in the other
files introduce names that are specified by the programmer.  This way,
it is easy to avoid name conflicts.


@defun lexer-make-IS @var{input-type} @var{input}
@defunx lexer-make-IS @var{input-type} @var{input} @var{counters}
Create an input system.  The arguments @var{input-type} and @var{input}
are described in @ref{using input}.  The value of @var{counters}
determines which counters the input system should maintain.  This is
discussed in @ref{using input}.  Input systems are associative lists
that cannot be used directly.
@end defun


Useful functions can be extracted from an input system.  The following
calls return functions that allows the program to interact with the
input system:

@example
(lexer-get-func-line   @var{input-system})
(lexer-get-func-column @var{input-system})
(lexer-get-func-offset @var{input-system})
(lexer-get-func-getc   @var{input-system})
(lexer-get-func-ungetc @var{input-system})
@end example


@defun lexer-make-lexer @var{table} @var{input-system}
Create a lexical analyser.  @var{table} is a table generated by SILex.
@var{input-system} is the input system from which the analyser will take
its input.  The result of the call is the analysis function.  The
analysis function takes no argument and returns tokens.
@end defun


This example summarizes all the step in the creation of an analyser:

@example
(let* ((my-port       (open-input-file "my-file"))
       (my-IS         (lexer-make-IS 'port my-port))
       (my-get-line   (lexer-get-func-line my-IS))
       (my-get-column (lexer-get-func-column my-IS))
       (my-get-offset (lexer-get-func-offset my-IS))
       (my-getc       (lexer-get-func-getc my-IS))
       (my-ungetc     (lexer-get-func-ungetc my-IS))
       (my-analyser   (lexer-make-lexer my-table my-IS)))
  (let loop ((tok (my-analyser)))
    (cond ((eq? tok 'eof)
           ---)
          ---)))
@end example

@c page
@node using options
@section Options at generation time


@cindex Options


We describe the options that can be passed to @func{lex} and
@func{lex-tables}.  They indicate which counters (line, column and
offset) the actions need; which table encoding should be used; and
whether the tables should be pretty-printed.

@menu
* using options counters::      Keeping the position in the input.
* using options tables::        Encodings of the tables of an
                                analyser.
* using options print::         Pretty printing the tables.
@end menu

@c page
@node using options counters
@subsection Line, column and offset counters


@cindex Counters
@vindex none
@vindex line
@vindex all


There are three different counting modes: no counter, line counter and
all counters.  The more counters the input system maintains, the more it
is slowed down.  The default is the line counting.

This option is specified when the program calls the functions
@func{lex}, @func{lex-tables} and @func{lexer-make-IS}.  The three modes
are represented by the symbols @samp{none}, @samp{line} and @samp{all}.
When one of the first two functions is called the mode must be preceded
by the symbol @samp{counters}.  These examples illustrate the use of the
option:

@example
(lex "html.l" "html.l.scm" 'counters 'none)

(lex-tables "cobol.l" "cobol-table" "cobol.l.scm" 'counters 'line)

(lexer-make-IS 'port my-port 'all)
@end example

We should be careful when building analysers dynamically.  The mode
specified at the input system creation must be consistent with the mode
specified at the tables creation.

@c page
@node using options tables
@subsection Encoding of the table of an analyser


@cindex Encoding of the table
@vindex portable
@vindex code
@cindex Portability
@cindex Fast analyser


SILex provides three different encodings of the tables: the default
encoding, the portable encoding and the ``compilation'' to Scheme code.

With the default encoding, the finite automaton of the analyser is
represented with data structures that contain the @emph{numbers} of the
characters (in the sense of @func{char->integer}).  Since the numbers
associated with the characters may depend on the Scheme implementation,
an analyser generated with an implementation can be safely used only
with the same implementation.  An analyser encoded in the default style
is not portable.  But this representation is the most compact.

With the portable encoding, the data structures describing the automaton
contain characters directly.  If the automaton, as generated, contains a
transition from state @var{s} to state @var{t} on character @var{c},
then somewhere in the table there is the Scheme character
@samp{#\@var{c}}.  When the file containing the analyser is loaded in
any implementation, the character is read as is, and not as the number
@samp{(char->integer #\@var{c})} as evaluated by the original
implementation.  As long as the implementation using the analyser
recognizes the characters mentionned in it, there is no problem.

So this encoding is portable.  However, it is less compact.  This is
because something like @samp{(65 90)} is more compact than something
like @samp{(#\A #\B @r{@dots{}} #\Y #\Z)} to represent @samp{[A-Z]}.
The construction of an analyser from a portable table takes more time
than the construction from a default table.  But, once built, the
performance of the analyser is the same in both cases.

It is important to note that in some character sets, the letters or the
digits are not contiguous.  So, in those cases, the regular expression
@samp{[A-Z]} does not necessarily accept only the uppercase letters.

The last encoding is the compilation to Scheme code.  This produces a
fast lexical analyser.  Instead of containing data structures
representing the behavior of the automaton, the table contains Scheme
code that ``hard--codes'' the automaton.  This encoding often generates
big tables.  Such an analyser is not portable.

The encoding of the tables can be specified as an option when @func{lex}
and @func{lex-tables} are called.  The symbols @samp{portable} and
@samp{code} are used to specify that the table must be portable and that
the table must be compiled, respectively.  For example, these calls
illustrate the use of the options:

@example
(lex "c.l" "c.l.scm")             ; Default encoding

(lex "c.l" "c.l.scm" 'portable)   ; Portable encoding

(lex "c.l" "c.l.scm" 'code)       ; Compilation of the automaton
@end example

@c page
@node using options print
@subsection Pretty printing the tables


@cindex Pretty-printing the tables


The pretty--print option (specified with the symbol @samp{pp}) tells
SILex to pretty--print the contents of the table.  Normally, the table
is displayed as a compact mass of characters fitting in about @math{75}
columns.  The option is useful only for a developer of SILex.  The
Scheme code generated with the @samp{code} option is always
pretty--printed.

@c page
@node using input
@section Input methods


@cindex Input
@cindex Input port, input from an
@cindex String, input from a
@cindex Function, input from a


An analyser can take its input from three different objects: an input
port, a string or a function.  The type of input and the input itself
must be passed when an analyser is initialized and when an input system
is created.  The input type is specified using one of the three symbols:
@samp{port}, @samp{string} or @samp{procedure}.  For example:

@example
(lexer-init 'port (current-input-port))

(lexer-make-IS 'string "Input string.")
@end example

When an input port is used by an analyser, the program should avoid
reading characters directly from the port.  This is because the analyser
may have needed a look-ahead to do the analysis of the preceding token.
The program would not find what it expects on the port.  The analyser
provides safe functions to get characters from the input.  The analyser
never closes itself the port it has received, this task is left to the
program.

When the analyser is initialized with a string, it takes a copy of it.
This way, eventual mutations of the string do not affect the analysis.

The use of a function as character source allows the analyser to parse
any character stream, no matter how it is obtained.  For example, the
characters may come from the decompression or decryption of a huge file,
the task being done lazily in order to save space.  The function must
take no argument and return a character each time it is called.  When
the end of file (or its logical equivalent) is reached, the function
must return an object that is not a character (for example, the symbol
@samp{eof}).  After the function has returned an end of file indicator,
it is not called again.

@c page
@node lalr
@appendix Interfacing with an @sc{lalr}(1) parser


@cindex Dominique Boucher
@cindex @sc{lalr}(1) parser generator


A nice @sc{lalr}(1) parser generator for Scheme has been written by
Dominique Boucher.

The parsers that are generated need two functions to operate: A lexical
analysis function and an error function.  The analysis function must
take no argument and return a token each time it is called.  This is
exactly the behavior of the lexical analysis functions created by SILex.

The @sc{lalr}(1) parsers expect that the tokens are pairs with a number
in the @sc{car}, the token number, and any value in the @sc{cdr}, the
token attribute.  It is easy to respect this convention with a SILex
lexical analyser since the actions can be any Scheme expressions.
Furthermore, the file created by the @sc{lalr}(1) parser generator
contains definitions that give names to the number of the tokens.  A
lexical analyser can use those names in its actions in order to simplify
the coordination between the two analysers.

@c page
@node ack
@appendix Acknowledgements


I would like to thank my comrades of the laboratory for their support in
this project.  Especially Martin Larose and Marc Feeley for their
numerous suggestions.

I hope SILex will be useful for many Scheme programmers.

@c page
@c ------------------------------------------------------------
@c Licenses.
@c ------------------------------------------------------------

@include gpl-3.0.texiinc
@include fdl-1.3.texiinc

@c page
@node references
@appendix Bibliography and references


The original version of SILex is available at:

@center @url{http://www.iro.umontreal.ca/~dube}

@c page
@node concept index
@appendix An entry for each concept

@printindex cp

@node function index
@appendix An entry for each function.

@printindex fn

@node variable index
@appendix An entry for each variable.

@printindex vr

@node type index
@appendix An entry for each type.

@printindex tp

@contents
@bye

@c end of file
